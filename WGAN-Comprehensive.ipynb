{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ WGAN-GP 3D Voxel Shape Generation Notebook\n",
    "\n",
    "**Project Title:** ShapeGAN Reboot ‚Äî Implementing WGAN-GP for 3D Chair Synthesis  \n",
    "**Student Name:** Yazdan Ghanavati\n",
    "**Course:** 3D Vision / ICT  \n",
    "**Date:** July 2025  \n",
    "**Institution:** University of Padova\n",
    "\n",
    "---\n",
    "\n",
    "### üìò Summary\n",
    "\n",
    "This notebook demonstrates the full implementation of a WGAN-GP (Wasserstein GAN with Gradient Penalty) architecture designed to generate 3D voxel representations of chairs. It uses Signed Distance Fields (SDFs) from the ShapeNet dataset and integrates custom training loops, sampling routines, and visualization tools ‚Äî all fully embedded for portability and transparency.\n",
    "\n",
    "üß± All code, data loading, optimization, and rendering are contained in the notebook. No external imports from local modules.\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Attribution\n",
    "\n",
    "Most architectural ideas and training flow were inspired by the open-source project:  \n",
    "üîó [marian42/shapegan](https://github.com/marian42/shapegan)\n",
    "\n",
    "This implementation adapts, restructures, and expands upon that foundation to support WGAN-GP with gradient penalties, checkpointing, and interactive shape previews.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç Section 0: Library Imports\n",
    "\n",
    "This cell imports all necessary libraries used throughout the notebook, including:\n",
    "- PyTorch for deep learning\n",
    "- NumPy for tensor and array manipulation\n",
    "- `os`, `re`, and `sys` for file and system operations\n",
    "- Visualization libraries such as `pygame` and `OpenGL` for 3D rendering\n",
    "- Skimage and Trimesh for mesh creation and processing\n",
    "\n",
    "üì¶ These imports cover model definitions, training loop, voxel handling, gradient penalty logic, and real-time previews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.10.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# Source: train_wgan.py (Global Imports)\n",
    "\n",
    "# --- Deep Learning & Data Handling ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.autograd as autograd  # For gradient penalty\n",
    "\n",
    "# --- Math, System & File Tools ---\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "\n",
    "# --- Visualization: 3D Viewer & Mesh ---\n",
    "import pygame  # type: ignore\n",
    "from pygame.locals import *\n",
    "import pygame.image\n",
    "\n",
    "from OpenGL.GL import *\n",
    "from OpenGL.GLU import *\n",
    "from OpenGL.arrays import vbo\n",
    "\n",
    "# --- Scientific & Rendering Tools ---\n",
    "import cv2\n",
    "import skimage.measure\n",
    "import trimesh\n",
    "from threading import Thread, Lock\n",
    "\n",
    "# üîß Custom Utilities (embedded separately later)\n",
    "# - create_text_slice()\n",
    "# - crop_image()\n",
    "# - get_camera_transform()\n",
    "# - MeshRenderer\n",
    "# - SavableModule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß∞ Section 1: Constants & Utility Definitions\n",
    "\n",
    "This section defines the foundational tools and parameters used throughout the notebook:\n",
    "\n",
    "- ‚öôÔ∏è `device`: Automatically selects CUDA or CPU for computation\n",
    "- üìä `standard_normal_distribution`: Enables Gaussian noise sampling for latent space\n",
    "- üìÅ Directory setup ensures output folders (`models`, `plots`, `data`) are created before use\n",
    "- üé® `create_text_slice()`: Converts a 2D slice of a voxel grid into an ASCII art preview for inline visualization\n",
    "- üß™ Additional helpers support image cropping, voxel coordinate generation, and 3D point sampling\n",
    "\n",
    "These utilities power data loading, model generation, shape rendering, and the training pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Source: util.py (Device setup, Distribution, Text Slice, Misc Tools)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- Hardware Selection ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# --- Standard Gaussian Noise Distribution for Latent Sampling ---\n",
    "standard_normal_distribution = torch.distributions.normal.Normal(0, 1)\n",
    "\n",
    "# --- Directory Setup ---\n",
    "def ensure_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "ensure_directory('plots')\n",
    "ensure_directory('models')\n",
    "ensure_directory('data')\n",
    "\n",
    "# --- ASCII Slice Renderer ---\n",
    "CHARACTERS = '      `.-:/+osyhdmm###############'\n",
    "\n",
    "def create_text_slice(voxels):\n",
    "    if isinstance(voxels, np.ndarray):\n",
    "        voxels = torch.from_numpy(voxels).float().to(device)\n",
    "    voxel_resolution = voxels.shape[-1]\n",
    "    center_slice_index = voxels.shape[0] // 4\n",
    "    data = voxels[center_slice_index, :, :]\n",
    "\n",
    "    data = torch.clamp(data * -0.5 + 0.5, 0, 1) * (len(CHARACTERS) - 1)\n",
    "    data = data.type(torch.int).cpu()\n",
    "    lines = ['|' + ''.join([CHARACTERS[i] for i in line]) + '|' for line in data]\n",
    "\n",
    "    frame = '+' + '‚Äî' * voxel_resolution + '+\\n'\n",
    "    return frame + '\\n'.join(lines) + '\\n' + frame\n",
    "\n",
    "# --- Optional Utilities ---\n",
    "def get_points_in_unit_sphere(n, device):\n",
    "    x = torch.rand(int(n * 2.5), 3, device=device) * 2 - 1\n",
    "    mask = (torch.norm(x, dim=1) < 1).nonzero().squeeze()\n",
    "    mask = mask[:n]\n",
    "    x = x[mask, :]\n",
    "    if x.shape[0] < n:\n",
    "        print(\"Warning: Did not find enough points.\")\n",
    "    return x\n",
    "\n",
    "def crop_image(image, background=255):\n",
    "    mask = image[:, :] != background\n",
    "    coords = np.array(np.nonzero(mask))\n",
    "    if coords.size != 0:\n",
    "        top_left = np.min(coords, axis=1)\n",
    "        bottom_right = np.max(coords, axis=1)\n",
    "    else:\n",
    "        top_left = np.array((0, 0))\n",
    "        bottom_right = np.array(image.shape)\n",
    "        print(\"Warning: Image contains only background pixels.\")\n",
    "    half_size = int(max(bottom_right[0] - top_left[0], bottom_right[1] - top_left[1]) / 2)\n",
    "    center = ((top_left + bottom_right) / 2).astype(int)\n",
    "    center = (min(max(half_size, center[0]), image.shape[0] - half_size),\n",
    "              min(max(half_size, center[1]), image.shape[1] - half_size))\n",
    "    if half_size > 100:\n",
    "        image = image[center[0] - half_size:center[0] + half_size,\n",
    "                      center[1] - half_size:center[1] + half_size]\n",
    "    return image\n",
    "\n",
    "def get_voxel_coordinates(resolution=32, size=1, center=0, return_torch_tensor=False):\n",
    "    if type(center) == int:\n",
    "        center = (center, center, center)\n",
    "    points = np.meshgrid(\n",
    "        np.linspace(center[0] - size, center[0] + size, resolution),\n",
    "        np.linspace(center[1] - size, center[1] + size, resolution),\n",
    "        np.linspace(center[2] - size, center[2] + size, resolution)\n",
    "    )\n",
    "    points = np.stack(points)\n",
    "    points = np.swapaxes(points, 1, 2)\n",
    "    points = points.reshape(3, -1).transpose()\n",
    "    if return_torch_tensor:\n",
    "        return torch.tensor(points, dtype=torch.float32, device=device)\n",
    "    else:\n",
    "        return points.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Section 2: Model Definitions (Generator, Critic, SavableModule)\n",
    "\n",
    "This section defines the two core neural networks used in the WGAN-GP framework:\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Generator\n",
    "\n",
    "- Uses transposed 3D convolution layers to convert a latent noise vector into a 3D voxel grid\n",
    "- Activations include BatchNorm and LeakyReLU for smooth gradient flow\n",
    "- Final layer uses `Tanh` to output values in the range [-1, 1], suitable for Signed Distance Fields (SDF)\n",
    "- Inherits from `SavableModule` to support saving/loading checkpoints\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Discriminator (Critic)\n",
    "\n",
    "- Uses 3D convolutions to assign scores to voxel shapes\n",
    "- No sigmoid applied at the output ‚Äî raw score is used to estimate Wasserstein distance\n",
    "- Includes BatchNorm layers for training stability\n",
    "- `use_sigmoid` flag determines whether to use traditional GAN output or WGAN-style critic scoring\n",
    "\n",
    "---\n",
    "\n",
    "### üß± SavableModule & Lambda\n",
    "\n",
    "- `SavableModule` is a lightweight base class that adds checkpointing logic to any PyTorch module\n",
    "- `Lambda` wraps arbitrary functions (like optional activations) into a layer-compatible object\n",
    "\n",
    "These models form the heart of shape synthesis and quality evaluation in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: init.py and gan.py (Generator, Critic, Lambda, SavableModule)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "LATENT_CODE_SIZE = 128\n",
    "MODEL_PATH = \"models\"\n",
    "CHECKPOINT_PATH = os.path.join(MODEL_PATH, 'checkpoints')\n",
    "\n",
    "# --- Lambda Layer Wrapper ---\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, function):\n",
    "        super(Lambda, self).__init__()\n",
    "        self.function = function\n",
    "    def forward(self, x):\n",
    "        return self.function(x)\n",
    "\n",
    "# --- Savable Base Module ---\n",
    "class SavableModule(nn.Module):\n",
    "    def __init__(self, filename):\n",
    "        super(SavableModule, self).__init__()\n",
    "        self.filename = filename\n",
    "\n",
    "    def get_filename(self, epoch=None, filename=None):\n",
    "        if filename is None:\n",
    "            filename = self.filename\n",
    "        if epoch is None:\n",
    "            return os.path.join(MODEL_PATH, filename)\n",
    "        else:\n",
    "            filename = filename.split('.')\n",
    "            filename[-2] += '-epoch-{:05d}'.format(epoch)\n",
    "            filename = '.'.join(filename)\n",
    "            return os.path.join(CHECKPOINT_PATH, filename)\n",
    "\n",
    "    def load(self, epoch=None, filename=None):\n",
    "        load_filename = filename if filename is not None else self.filename\n",
    "        self.load_state_dict(torch.load(self.get_filename(epoch=epoch, filename=load_filename)), strict=False)\n",
    "\n",
    "    def save(self, epoch=None):\n",
    "        if epoch is not None and not os.path.exists(CHECKPOINT_PATH):\n",
    "            os.makedirs(CHECKPOINT_PATH)\n",
    "        torch.save(self.state_dict(), self.get_filename(epoch=epoch))\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "# --- Generator (WGAN-GP Style) ---\n",
    "class Generator(SavableModule):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__(filename=\"generator_wgan.to\")\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.ConvTranspose3d(LATENT_CODE_SIZE, 256, 4, 1),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.ConvTranspose3d(256, 128, 4, 2, 1),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.ConvTranspose3d(128, 64, 4, 2, 1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.ConvTranspose3d(64, 1, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape((-1, LATENT_CODE_SIZE, 1, 1, 1))\n",
    "        return self.layers(x)\n",
    "\n",
    "    def generate(self, sample_size=1):\n",
    "        shape = torch.Size((sample_size, LATENT_CODE_SIZE))\n",
    "        x = standard_normal_distribution.sample(shape).to(self.device)\n",
    "        return self(x)\n",
    "\n",
    "# --- Discriminator (Critic with Raw Output) ---\n",
    "class Discriminator(SavableModule):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__(filename=\"discriminator_wgan.to\")\n",
    "        self.use_sigmoid = False  # For WGAN-GP: raw score, no sigmoid\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv3d(1, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv3d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv3d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv3d(256, 1, 4, 1, 0, bias=False),\n",
    "            Lambda(lambda x: torch.sigmoid(x) if self.use_sigmoid else x)\n",
    "        )\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.ndim < 5:\n",
    "            x = x.unsqueeze(1)\n",
    "        return self.layers(x).view(-1, 1)\n",
    "\n",
    "    def clip_weights(self, value):\n",
    "        for parameter in self.parameters():\n",
    "            parameter.data.clamp_(-value, value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåä Section 3: WGAN-GP Gradient Penalty Function\n",
    "\n",
    "One of the key innovations of WGAN-GP over vanilla GANs is its use of a gradient penalty to enforce the Lipschitz constraint on the Critic (Discriminator). This replaces traditional weight clipping, offering smoother optimization and better stability.\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Purpose of `calc_gradient_penalty()`\n",
    "\n",
    "- Calculates the **gradient norm** of the Critic with respect to interpolated samples\n",
    "- Penalizes deviations from a norm of 1, encouraging more well-behaved gradients\n",
    "- Uses PyTorch‚Äôs `autograd.grad()` to compute gradients for inputs with `requires_grad=True`\n",
    "\n",
    "---\n",
    "\n",
    "### üìå How It Works\n",
    "\n",
    "1. **Interpolation**: Mixes real and fake samples\n",
    "2. **Forward Pass**: Computes the Critic score for these interpolates\n",
    "3. **Gradient Calculation**: Derives the Critic's gradient w.r.t inputs\n",
    "4. **Penalty**: Applies penalty proportional to deviation from unit norm\n",
    "\n",
    "This function is invoked during each Discriminator update step to stabilize training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: train_wgan.py (WGAN-GP Gradient Penalty Function)\n",
    "\n",
    "def calc_gradient_penalty(discriminator, real_data, fake_data, lambda_gp=10.0):\n",
    "    batch_size = real_data.size(0)\n",
    "    alpha = torch.rand(batch_size, 1, 1, 1, 1, device=device)\n",
    "    \n",
    "    # Interpolate between real and fake samples\n",
    "    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "    interpolates.requires_grad_(True)\n",
    "\n",
    "    # Evaluate discriminator on interpolated data\n",
    "    disc_interpolates = discriminator(interpolates)\n",
    "\n",
    "    # Compute gradients of outputs w.r.t inputs\n",
    "    gradients = autograd.grad(\n",
    "        outputs=disc_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=torch.ones_like(disc_interpolates),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "\n",
    "    # Flatten and compute gradient norm\n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    gradient_norm = gradients.norm(2, dim=1)\n",
    "\n",
    "    # Compute penalty: deviation from unit norm\n",
    "    gradient_penalty = lambda_gp * ((gradient_norm - 1) ** 2).mean()\n",
    "    return gradient_penalty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîÅ Section 4: WGAN-GP Training Loop\n",
    "\n",
    "This section defines the complete training procedure for both the Generator and Critic using the WGAN-GP framework. The process follows a carefully balanced update strategy to ensure stable learning:\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Critic Optimization\n",
    "- The Critic is updated multiple times per Generator update (`critic_iterations`)\n",
    "- Calculates real and fake scores, and applies the **gradient penalty** to enforce Lipschitz continuity\n",
    "\n",
    "---\n",
    "\n",
    "### üé® Generator Optimization\n",
    "- The Generator is updated once per cycle to fool the Critic\n",
    "- Uses the negative of the Critic‚Äôs score on generated samples as its loss\n",
    "\n",
    "---\n",
    "\n",
    "### üìã Features in the Training Loop\n",
    "- Models saved every `save_every` epochs\n",
    "- Voxel outputs visualized in ASCII using `create_text_slice()`\n",
    "- Metrics logged: Critic loss, Generator loss, Gradient penalty\n",
    "- Samples generated at `preview_every` intervals for inline display\n",
    "\n",
    "This loop is the heartbeat of the notebook ‚Äî training the networks to generate realistic, high-quality 3D shapes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: train_wgan.py (Main Training Loop for WGAN-GP)\n",
    "\n",
    "def train_wgan(generator, discriminator, dataloader, epochs=100, critic_iterations=5, save_every=10, preview_every=10):\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i, real_data in enumerate(dataloader):\n",
    "            real_data = real_data.to(device)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Critic\n",
    "            # ---------------------\n",
    "            for _ in range(critic_iterations):\n",
    "                discriminator.zero_grad()\n",
    "\n",
    "                # Generate fake data\n",
    "                fake_data = generator.generate(sample_size=real_data.size(0))\n",
    "\n",
    "                # Critic loss components\n",
    "                score_real = discriminator(real_data).mean()\n",
    "                score_fake = discriminator(fake_data.detach()).mean()\n",
    "                gradient_penalty = calc_gradient_penalty(discriminator, real_data, fake_data.detach())\n",
    "\n",
    "                loss_D = score_fake - score_real + gradient_penalty\n",
    "                loss_D.backward()\n",
    "                optimizer_D.step()\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "            generator.zero_grad()\n",
    "\n",
    "            fake_data = generator.generate(sample_size=real_data.size(0))\n",
    "            score = discriminator(fake_data)\n",
    "            loss_G = -score.mean()\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "        # --- Logging ---\n",
    "        print(f\"[Epoch {epoch+1}/{epochs}] Loss_D: {loss_D.item():.4f}, Loss_G: {loss_G.item():.4f}, GP: {gradient_penalty.item():.4f}\")\n",
    "\n",
    "        # --- Preview Output ---\n",
    "        if (epoch + 1) % preview_every == 0:\n",
    "            preview = generator.generate().detach().cpu().squeeze()\n",
    "            print(create_text_slice(preview))\n",
    "\n",
    "        # --- Save Models ---\n",
    "        if (epoch + 1) % save_every == 0:\n",
    "            generator.save(epoch + 1)\n",
    "            discriminator.save(epoch + 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì¶ Section 5: Data Loading with `VoxelDataset`\n",
    "\n",
    "This section defines the `VoxelDataset` class, which is responsible for loading 3D voxel data stored in `.npy` files. These files typically represent Signed Distance Fields (SDFs) extracted from the ShapeNet dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† What `VoxelDataset` Does\n",
    "- Loads voxel grids from a list of file paths\n",
    "- Clamps and normalizes SDF values to a usable range\n",
    "- Provides PyTorch compatibility for use in `DataLoader`\n",
    "- Includes convenient static methods to load datasets via glob patterns or split lists\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Features\n",
    "- `clamp`: Controls truncation limits for extreme SDF values\n",
    "- `rescale_sdf`: Normalizes the values to [-1, 1] after clamping\n",
    "- `glob(pattern)`: Finds and sorts voxel files based on a glob path\n",
    "- `from_split(pattern, split_file)`: Loads files using an external split list\n",
    "- `show()`: Allows visual inspection of samples using real-time rendering\n",
    "\n",
    "This class gives structure and control over dataset usage during training and previewing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: voxel_dataset.py (VoxelDataset Class for Data Loading)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class VoxelDataset(Dataset):\n",
    "    def __init__(self, files, clamp=0.1, rescale_sdf=True):\n",
    "        self.files = files\n",
    "        self.clamp = clamp\n",
    "        self.rescale_sdf = rescale_sdf\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        array = np.load(self.files[index])\n",
    "        result = torch.from_numpy(array)\n",
    "        if self.clamp is not None:\n",
    "            result.clamp_(-self.clamp, self.clamp)\n",
    "            if self.rescale_sdf:\n",
    "                result /= self.clamp\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def glob(pattern):\n",
    "        import glob\n",
    "        files = glob.glob(pattern, recursive=True)\n",
    "        if len(files) == 0:\n",
    "            raise Exception(f'No files found for glob pattern {pattern}.')\n",
    "        return VoxelDataset(sorted(files))\n",
    "\n",
    "    @staticmethod\n",
    "    def from_split(pattern, split_file_name):\n",
    "        with open(split_file_name, 'r') as split_file:\n",
    "            ids = split_file.readlines()\n",
    "        files = [pattern.format(id.strip()) for id in ids]\n",
    "        files = [file for file in files if os.path.exists(file)]\n",
    "        return VoxelDataset(files)\n",
    "\n",
    "    def show(self):\n",
    "        from rendering import MeshRenderer\n",
    "        import time\n",
    "        from tqdm import tqdm\n",
    "\n",
    "        viewer = MeshRenderer()\n",
    "        for item in tqdm(self):\n",
    "            viewer.set_voxels(item.numpy())\n",
    "            time.sleep(0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé• Section 6: Shape Visualization with `MeshRenderer`\n",
    "\n",
    "This section enables real-time 3D rendering of voxel shapes using OpenGL and PyGame. It builds a flexible and efficient viewer that can display both generated and training set shapes with shading, lighting, floor reference, and rotation controls.\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Features of `MeshRenderer`\n",
    "\n",
    "- Uses **marching cubes** to convert binary voxel grids or SDFs into 3D meshes\n",
    "- Renders shapes with custom shaders for light and shadow control\n",
    "- Visualizes shape geometry from latent codes during training\n",
    "- Includes real-time preview options with mouse-controlled rotation\n",
    "- Floor plane support for grounding visuals and spatial reference\n",
    "\n",
    "---\n",
    "\n",
    "### ü™û Preview Utilities\n",
    "- `set_voxels(voxels)`: Converts a voxel grid into a mesh and updates OpenGL buffers\n",
    "- `set_mesh(mesh)`: Renders a precomputed mesh (e.g., via `trimesh`)\n",
    "- `get_image()`: Captures the rendering window into a NumPy image\n",
    "- `save_screenshot()`: Stores the current frame as a PNG\n",
    "\n",
    "This viewer is used during model training and debugging to inspect voxel outputs in a spatially meaningful way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: rendering.py (MeshRenderer Class for 3D Voxel Visualization)\n",
    "\n",
    "import numpy as np\n",
    "import pygame\n",
    "import os\n",
    "from OpenGL.GL import *\n",
    "from OpenGL.arrays import vbo\n",
    "import trimesh\n",
    "\n",
    "SHADOW_TEXTURE_SIZE = 1024\n",
    "DEFAULT_ROTATION = [25, 15]\n",
    "\n",
    "class MeshRenderer:\n",
    "    def __init__(self, size=512):\n",
    "        self.size = size\n",
    "        self.model_color = [1.0, 1.0, 1.0]\n",
    "        self.background_color = [0.2, 0.2, 0.2, 1]\n",
    "        self.model_size = 1.0\n",
    "        self.rotation = list(DEFAULT_ROTATION)\n",
    "        self.render_lock = Lock()\n",
    "        self.mouse = None\n",
    "        self.request_render = True\n",
    "        self.running = True\n",
    "        self.vertex_buffer = None\n",
    "        self.normal_buffer = None\n",
    "\n",
    "    def set_voxels(self, voxels):\n",
    "        marching_cubes = skimage.measure.marching_cubes(\n",
    "            voxels, level=0.0, spacing=(1.0 / voxels.shape[0],) * 3)\n",
    "        mesh = trimesh.Trimesh(vertices=marching_cubes[0], faces=marching_cubes[1])\n",
    "        self.set_mesh(mesh, smooth=False, center_and_scale=True)\n",
    "\n",
    "    def set_mesh(self, mesh, smooth=False, center_and_scale=False):\n",
    "        if mesh is None:\n",
    "            return\n",
    "\n",
    "        vertices = np.array(mesh.triangles, dtype=np.float32).reshape(-1, 3)\n",
    "        if center_and_scale:\n",
    "            vertices -= mesh.bounding_box.centroid[np.newaxis, :]\n",
    "            vertices /= np.max(np.linalg.norm(vertices, axis=1))\n",
    "        self.ground_level = np.min(vertices[:, 1]).item()\n",
    "        vertices = vertices.reshape((-1))\n",
    "\n",
    "        if smooth:\n",
    "            normals = mesh.vertex_normals[mesh.faces.reshape(-1)].astype(np.float32) * -1\n",
    "        else:\n",
    "            normals = np.repeat(mesh.face_normals, 3, axis=0).astype(np.float32)\n",
    "\n",
    "        self._update_buffers(vertices, normals)\n",
    "        self.model_size = 1.08\n",
    "\n",
    "    def _update_buffers(self, vertices, normals):\n",
    "        self.vertex_buffer = vbo.VBO(vertices)\n",
    "        self.normal_buffer = vbo.VBO(normals)\n",
    "        self.vertex_buffer_size = len(vertices) // 3\n",
    "\n",
    "    def _poll_mouse(self):\n",
    "        left_mouse, _, right_mouse = pygame.mouse.get_pressed()\n",
    "        pressed = left_mouse == 1 or right_mouse == 1\n",
    "        current_mouse = pygame.mouse.get_pos()\n",
    "        if self.mouse is not None and pressed:\n",
    "            movement = (current_mouse[0] - self.mouse[0], current_mouse[1] - self.mouse[1])\n",
    "            self.rotation = [self.rotation[0] + movement[0], max(-90, min(90, self.rotation[1] + movement[1]))]\n",
    "        self.mouse = current_mouse\n",
    "        return pressed\n",
    "\n",
    "    def _draw_mesh(self, use_normals=True):\n",
    "        if self.vertex_buffer is None or self.normal_buffer is None:\n",
    "            return\n",
    "        glEnableClientState(GL_VERTEX_ARRAY)\n",
    "        self.vertex_buffer.bind()\n",
    "        glVertexPointer(3, GL_FLOAT, 0, self.vertex_buffer)\n",
    "        if use_normals:\n",
    "            glEnableClientState(GL_NORMAL_ARRAY)\n",
    "            self.normal_buffer.bind()\n",
    "            glNormalPointer(GL_FLOAT, 0, self.normal_buffer)\n",
    "        glDrawArrays(GL_TRIANGLES, 0, self.vertex_buffer_size)\n",
    "\n",
    "    def prepare_floor(self):\n",
    "        size = 6\n",
    "        mesh = trimesh.Trimesh([\n",
    "            [-size, 0, -size], [-size, 0, +size], [+size, 0, +size],\n",
    "            [-size, 0, -size], [+size, 0, +size], [+size, 0, -size]\n",
    "        ], faces=[[0, 1, 2], [3, 4, 5]])\n",
    "        vertices = np.array(mesh.triangles, dtype=np.float32).reshape(-1, 3)\n",
    "        normals = np.repeat(mesh.face_normals, 3, axis=0).astype(np.float32)\n",
    "        self.floor_vertices = vbo.VBO(vertices.reshape(-1))\n",
    "        self.floor_normals = vbo.VBO(normals)\n",
    "\n",
    "    def _draw_floor(self):\n",
    "        self.shader.set_y_offset(self.ground_level)\n",
    "        glEnableClientState(GL_VERTEX_ARRAY)\n",
    "        self.floor_vertices.bind()\n",
    "        glVertexPointer(3, GL_FLOAT, 0, self.floor_vertices)\n",
    "        glEnableClientState(GL_NORMAL_ARRAY)\n",
    "        self.floor_normals.bind()\n",
    "        glNormalPointer(GL_FLOAT, 0, self.floor_normals)\n",
    "        glDrawArrays(GL_TRIANGLES, 0, 6)\n",
    "\n",
    "    def _initialize_opengl(self):\n",
    "        pygame.init()\n",
    "        pygame.display.set_caption('Model Viewer')\n",
    "        pygame.display.gl_set_attribute(pygame.GL_MULTISAMPLEBUFFERS, 1)\n",
    "        pygame.display.gl_set_attribute(pygame.GL_MULTISAMPLESAMPLES, 4)\n",
    "        self.window = pygame.display.set_mode((self.size, self.size), pygame.OPENGLBLIT)\n",
    "\n",
    "        self.shader = Shader()\n",
    "        script_dir = os.path.dirname(__file__)\n",
    "        self.shader.initShader(\n",
    "            open(os.path.join(script_dir, 'vertex.glsl')).read(),\n",
    "            open(os.path.join(script_dir, 'fragment.glsl')).read()\n",
    "        )\n",
    "\n",
    "        self.shadow_framebuffer = glGenFramebuffers(1)\n",
    "        self.shadow_texture = create_shadow_texture()\n",
    "\n",
    "        self.depth_shader = Shader()\n",
    "        self.depth_shader.initShader(\n",
    "            open(os.path.join(script_dir, 'depth_vertex.glsl')).read(),\n",
    "            open(os.path.join(script_dir, 'depth_fragment.glsl')).read()\n",
    "        )\n",
    "\n",
    "        self.prepare_floor()\n",
    "\n",
    "    def _render_shadow_texture(self, light_vp_matrix):\n",
    "        glBindFramebuffer(GL_FRAMEBUFFER, self.shadow_framebuffer)\n",
    "        glFramebufferTexture2D(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_TEXTURE_2D, self.shadow_texture, 0)\n",
    "        glDrawBuffer(GL_NONE)\n",
    "        glReadBuffer(GL_NONE)\n",
    "        glClear(GL_DEPTH_BUFFER_BIT)\n",
    "        glViewport(0, 0, SHADOW_TEXTURE_SIZE, SHADOW_TEXTURE_SIZE)\n",
    "        glEnable(GL_DEPTH_TEST)\n",
    "        glDepthMask(GL_TRUE)\n",
    "        glDepthFunc(GL_LESS)\n",
    "        glDepthRange(0.0, 1.0)\n",
    "        glDisable(GL_CULL_FACE)\n",
    "        glDisable(GL_BLEND)\n",
    "\n",
    "        self.depth_shader.use()\n",
    "        self.depth_shader.set_vp_matrix(light_vp_matrix)\n",
    "        self._draw_mesh(use_normals=False)\n",
    "\n",
    "        glBindFramebuffer(GL_FRAMEBUFFER, 0)\n",
    "\n",
    "    def _render(self):\n",
    "        self.request_render = False\n",
    "        self.render_lock.acquire()\n",
    "\n",
    "        light_vp_matrix = get_camera_transform(6, self.rotation[0], 50, project=True)\n",
    "        self._render_shadow_texture(light_vp_matrix)\n",
    "\n",
    "        self.shader.use()\n",
    "        self.shader.set_floor(False)\n",
    "        self.shader.set_color(self.model_color)\n",
    "        self.shader.set_y_offset(0)\n",
    "        camera_vp_matrix = get_camera_transform(self.model_size * 2, self.rotation[0], self.rotation[1], project=True)\n",
    "        self.shader.set_vp_matrix(camera_vp_matrix)\n",
    "        self.shader.set_light_vp_matrix(light_vp_matrix)\n",
    "\n",
    "        glClearColor(*self.background_color)\n",
    "        glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)\n",
    "        glClearDepth(1.0)\n",
    "        glDepthMask(GL_TRUE)\n",
    "        glDepthFunc(GL_LESS)\n",
    "        glDepthRange(0.0, 1.0)\n",
    "        glEnable(GL_CULL_FACE)\n",
    "        glEnable(GL_DEPTH_TEST)\n",
    "        glViewport(0, 0, self.size, self.size)\n",
    "\n",
    "        glActiveTexture(GL_TEXTURE1)\n",
    "        glBindTexture(GL_TEXTURE_2D, self.shadow_texture)\n",
    "        self.shader.set_shadow_texture(1)\n",
    "\n",
    "        self._draw_mesh()\n",
    "        self.shader.set_floor(True)\n",
    "        self._draw_floor()\n",
    "        self.render_lock.release()\n",
    "\n",
    "    def _run(self):\n",
    "        self._initialize_opengl()\n",
    "        self._render()\n",
    "        while self.running:\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    pygame.quit()\n",
    "                    return\n",
    "                if event.type == pygame.KEYDOWN:\n",
    "                    if pygame.key.get_pressed()[pygame.K_F12]:\n",
    "                        self.save_screenshot()\n",
    "                    if pygame.key.get_pressed()[pygame.K_r]:\n",
    "                        self.rotation = list(DEFAULT_ROTATION)\n",
    "                        self.request_render = True\n",
    "            if self._poll_mouse() or self.request_render:\n",
    "                self._render()\n",
    "                pygame.display.flip()\n",
    "            pygame.time.wait(10)\n",
    "        self.delete_buffers()\n",
    "\n",
    "    def get_image(self, crop=False, output_size=None, greyscale=False, flip_red_blue=False):\n",
    "        if self.request_render:\n",
    "            self._render()\n",
    "        if output_size is None:\n",
    "            output_size = self.size\n",
    "        string_image = pygame.image.tostring(self.window, 'RGB')\n",
    "        image = pygame.image.fromstring(string_image, (self.size, self.size), 'RGB')\n",
    "        if greyscale:\n",
    "            array = np.transpose(pygame.surfarray.array3d(image)[:, :, 0])\n",
    "        else:\n",
    "            array = np.transpose(pygame.surfarray.array3d(image)[:, :, (2, 1, 0) if flip_red_blue else slice(None)], (1, 0, 2))\n",
    "        if crop:\n",
    "            array = crop_image(array)\n",
    "        if output_size != self.size:\n",
    "            array = cv2.resize(array, dsize=(output_size, output_size), interpolation=cv2.INTER_CUBIC)\n",
    "        return array\n",
    "\n",
    "    def save_screenshot(self):\n",
    "        ensure_directory('screenshots')\n",
    "        FILENAME_FORMAT = \"screenshots/{:04d}.png\"\n",
    "        index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç Section 7: Inference & 3D Sample Visualization\n",
    "\n",
    "Now that the Generator is trained and saved at specific epochs, we can inspect its output using this embedded sampling and viewing routine.\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ What It Does\n",
    "- Loads a Generator checkpoint (e.g., `epoch_140`)\n",
    "- Generates a few voxel samples using random latent vectors\n",
    "- Displays their 2D slices in ASCII format using `create_text_slice()`\n",
    "- Optionally launches a 3D mesh viewer (`MeshRenderer`) if OpenGL rendering is available\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Parameters\n",
    "- `EPOCH_TO_LOAD`: Defines which checkpoint to inspect\n",
    "- `NUM_SAMPLES`: Number of fake voxel grids to generate\n",
    "- `ENABLE_3D_VIEWER`: Flag that enables OpenGL mesh visualization\n",
    "\n",
    "This block is ideal for evaluating the quality and diversity of generated shapes after training ‚Äî either inline in the notebook or with rich 3D previews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # üîç Inference & Viewer Logic from generate_and_view.py\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "# --- Constants ---\n",
    "MODEL_PATH = \"models\"\n",
    "CHECKPOINT_PATH = os.path.join(MODEL_PATH, 'checkpoints')\n",
    "EPOCH_TO_LOAD = 140\n",
    "NUM_SAMPLES = 3\n",
    "\n",
    "# --- Load Generator ---\n",
    "generator = Generator()\n",
    "try:\n",
    "    generator.load(epoch=EPOCH_TO_LOAD, filename=\"generator_wgan.to\")\n",
    "    generator.eval()\n",
    "    print(f\"‚úÖ Generator loaded successfully from epoch {EPOCH_TO_LOAD}\")\n",
    "except FileNotFoundError:\n",
    "    base_filename = \"generator_wgan.to\"\n",
    "    filename_parts = base_filename.split('.')\n",
    "    filename_parts[-2] += f'-epoch-{EPOCH_TO_LOAD:05d}'\n",
    "    expected_filename = '.'.join(filename_parts)\n",
    "    expected_path = os.path.join(CHECKPOINT_PATH, expected_filename)\n",
    "    print(f\"‚ùå Generator checkpoint not found: {expected_path}\")\n",
    "    print(\"Please verify that training ran long enough and model exists.\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Unexpected error loading Generator: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# --- Viewer Setup ---\n",
    "ENABLE_3D_VIEWER = True\n",
    "viewer = None\n",
    "try:\n",
    "    viewer = MeshRenderer()\n",
    "    print(\"üü¢ 3D viewer initialized\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è MeshRenderer init failed: {e}\")\n",
    "    ENABLE_3D_VIEWER = False\n",
    "\n",
    "# --- Sample Generation ---\n",
    "print(f\"\\nüé® Generating {NUM_SAMPLES} voxel samples...\")\n",
    "with torch.no_grad():\n",
    "    for i in range(NUM_SAMPLES):\n",
    "        voxel_tensor = generator.generate(sample_size=1)\n",
    "        voxel_numpy = voxel_tensor.squeeze().cpu().numpy()\n",
    "\n",
    "        print(f\"\\n--- Sample {i+1} (2D Slice Preview) ---\")\n",
    "        if voxel_numpy.shape == (32, 32, 32):\n",
    "            print(create_text_slice(voxel_numpy))\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Unexpected shape: {voxel_numpy.shape}\")\n",
    "            print(voxel_numpy[:5, :5, :5])\n",
    "\n",
    "        if ENABLE_3D_VIEWER and viewer:\n",
    "            try:\n",
    "                viewer.set_voxels(voxel_numpy, level=0.0)\n",
    "                print(f\"üßä Sample {i+1} sent to 3D viewer\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error visualizing Sample {i+1}: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Inference complete. Close 3D window(s) manually if open.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Section 8: Entry Point and Execution\n",
    "\n",
    "This block initializes the Generator and Discriminator, optionally resumes training from the last saved checkpoint, opens a log file to track metrics, and starts the training loop.\n",
    "\n",
    "‚úÖ You can adjust `start_epoch`, `total_epochs`, or checkpoint paths here. By wrapping the logic in `if __name__ == '__main__':`, it stays safe in both notebook and script form.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: train_wgan.py\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- Resume from last saved epoch ---\n",
    "    def find_last_saved_epoch(filename=\"generator_wgan.to\"):\n",
    "        if not os.path.exists(CHECKPOINT_PATH):\n",
    "            return 0\n",
    "        files = sorted([\n",
    "            f for f in os.listdir(CHECKPOINT_PATH)\n",
    "            if f.startswith(filename.split('.')[0]) and f.endswith('.to')\n",
    "        ])\n",
    "        if not files:\n",
    "            return 0\n",
    "        last_file = files[-1]\n",
    "        import re\n",
    "        match = re.search(r'epoch-(\\d+)', last_file)\n",
    "        return int(match.group(1)) if match else 0\n",
    "\n",
    "    start_epoch = find_last_saved_epoch()\n",
    "    print(f\"Resuming from epoch {start_epoch}...\")\n",
    "    generator = Generator()\n",
    "    discriminator = Discriminator()\n",
    "\n",
    "    if start_epoch > 0:\n",
    "        generator.load(epoch=start_epoch)\n",
    "        discriminator.load(epoch=start_epoch)\n",
    "        print(\"‚úÖ Models loaded from checkpoint.\")\n",
    "\n",
    "    # --- Logging Setup ---\n",
    "    log_filename = os.path.join(MODEL_PATH, \"log.txt\")\n",
    "    log_file = open(log_filename, \"a\")\n",
    "\n",
    "    # --- Dataset ---\n",
    "    dataset = VoxelDataset.glob(\"data/YOUR_DATA_PATH/**/*.npy\")\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    # --- Begin Training ---\n",
    "    train_wgan(generator, discriminator, dataloader, epochs=150)\n",
    "\n",
    "    log_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
