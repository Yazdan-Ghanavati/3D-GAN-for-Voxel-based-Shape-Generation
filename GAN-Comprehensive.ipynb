{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† GAN for 3D Voxel Shape Generation\n",
    "\n",
    "**Project Title:** ShapeGAN ‚Äî Generating 3D Voxel Chairs with Generative Adversarial Networks\n",
    "\n",
    "**Student Name:** Yazdan Ghanavati\n",
    "\n",
    "**Course:** 3D Vision / ICT  \n",
    "\n",
    "**Date:** July 2025  \n",
    "\n",
    "**Institution:** University of Padova\n",
    "\n",
    "---\n",
    "\n",
    "### üìç Project Summary\n",
    "\n",
    "This notebook presents a complete pipeline for training a Generative Adversarial Network (GAN) to synthesize 3D voxel-based shapes. It uses chair models from the ShapeNet dataset, represented as signed distance fields in `.npy` format, and trains a Generator and Discriminator using PyTorch.\n",
    "\n",
    "üõ† The entire codebase is embedded directly in the notebook for portability, clarity, and grading convenience.\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Inspiration\n",
    "\n",
    "> Most of the original code structure and core ideas were inspired by the open-source repository:\n",
    "> [marian42/shapegan](https://github.com/marian42/shapegan)\n",
    "\n",
    "This project builds upon ShapeGAN‚Äôs foundational ideas and adapts them into a compact, streamlined notebook format suitable for academic demonstration and hands-on experimentation.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Highlights\n",
    "\n",
    "- Fully embedded GAN architecture (Generator & Discriminator) using 3D convolutions\n",
    "- Integrated training loop with checkpoint resumption\n",
    "- Voxel shape generation with slice-based ASCII visualization\n",
    "- Optional rendering support for 3D previews\n",
    "- No external imports ‚Äî everything is self-contained\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì¶ Section 1: Imports and Device Setup\n",
    "\n",
    "This section loads all required Python packages for the GAN pipeline, including PyTorch for deep learning, NumPy for numerical operations, and utilities for file handling. It also detects whether a GPU is available and sets the correct device for computation.\n",
    "\n",
    "üí° Using CUDA if available ensures faster training and generation.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Source: util.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Set device based on availability (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è Section 2: Configuration and Hyperparameters\n",
    "\n",
    "This section defines all the key training and dataset parameters for the GAN model. It includes file paths for saving checkpoints, model settings like batch size and learning rate, and the location of the voxel data.\n",
    "\n",
    "üìå These values shape how your GAN learns and where it stores outputs. Updating them here ensures consistency across your pipeline.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: train_gan.py\n",
    "\n",
    "# --- Define Paths ---\n",
    "MODEL_PATH = \"models\"\n",
    "CHECKPOINT_PATH = os.path.join(MODEL_PATH, 'checkpoints')\n",
    "\n",
    "# Create model directories if they don't exist\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)\n",
    "if not os.path.exists(CHECKPOINT_PATH):\n",
    "    os.makedirs(CHECKPOINT_PATH)\n",
    "\n",
    "# --- Training Parameters ---\n",
    "BATCH_SIZE = 32\n",
    "TOTAL_TARGET_EPOCHS = 160\n",
    "SAVE_EVERY_N_EPOCHS = 10\n",
    "\n",
    "LEARNING_RATE_G = 0.0002\n",
    "LEARNING_RATE_D = 0.0002\n",
    "BETA1 = 0.5\n",
    "LATENT_CODE_SIZE = 128\n",
    "\n",
    "# --- Data Path & Workers ---\n",
    "DATASET_PATH = 'C:/Users/yghan/Documents/ICT/3D-Vision/test/dataset/ShapeNet_SDF/chairs/voxels_32/*.npy'\n",
    "NUM_WORKERS = 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üóÇÔ∏è Section 3: Dataset Loading\n",
    "\n",
    "This section uses the `VoxelDataset` class to load voxel data files from the ShapeNet dataset. These 3D shapes are represented as `.npy` files containing signed distance fields (SDFs). The dataset loader normalizes the values and prepares batches for training.\n",
    "\n",
    "üíæ By using `VoxelDataset.glob()`, the script searches through the specified folder and loads every `.npy` file matching the pattern.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from: C:/Users/yghan/Documents/ICT/3D-Vision/test/dataset/ShapeNet_SDF/chairs/voxels_32/*.npy\n",
      "Dataset loaded. Found 6232 samples.\n"
     ]
    }
   ],
   "source": [
    "# Source: train_gan.py + datasets.py\n",
    "\n",
    "from datasets import VoxelDataset\n",
    "\n",
    "# Load voxel dataset from files matching the glob pattern\n",
    "print(f\"Loading dataset from: {DATASET_PATH}\")\n",
    "dataset = VoxelDataset.glob(DATASET_PATH)\n",
    "\n",
    "# Wrap the dataset in a PyTorch DataLoader for batching\n",
    "data_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset loaded. Found {len(dataset)} samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Section 4: Model Definitions (Generator & Discriminator)\n",
    "\n",
    "This section defines the neural networks used in the GAN pipeline. The `Generator` uses 3D transposed convolutions to transform random noise vectors into voxel-based shapes, while the `Discriminator` tries to distinguish between real and fake voxel inputs using 3D convolutional layers.\n",
    "\n",
    "üß© Both models inherit from `SavableModule`, allowing them to be saved and loaded from checkpoints during training and evaluation. Their architectures are tuned for voxel resolution 32√ó32√ó32, which matches the dataset format.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: Combined from init.py, gan.py, util.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# --- Constants & Utility Setup ---\n",
    "LATENT_CODE_SIZE = 128\n",
    "MODEL_PATH = \"models\"\n",
    "CHECKPOINT_PATH = os.path.join(MODEL_PATH, 'checkpoints')\n",
    "standard_normal_distribution = torch.distributions.normal.Normal(0, 1)\n",
    "\n",
    "# --- SavableModule Base Class ---\n",
    "class SavableModule(nn.Module):\n",
    "    def __init__(self, filename):\n",
    "        super(SavableModule, self).__init__()\n",
    "        self.filename = filename\n",
    "\n",
    "    def get_filename(self, epoch=None, filename=None):\n",
    "        if filename is None:\n",
    "            filename = self.filename\n",
    "        if epoch is None:\n",
    "            return os.path.join(MODEL_PATH, filename)\n",
    "        else:\n",
    "            filename = filename.split('.')\n",
    "            filename[-2] += '-epoch-{:05d}'.format(epoch)\n",
    "            filename = '.'.join(filename)\n",
    "            return os.path.join(CHECKPOINT_PATH, filename)\n",
    "\n",
    "    def load(self, epoch=None):\n",
    "        self.load_state_dict(torch.load(self.get_filename(epoch=epoch)), strict=False)\n",
    "\n",
    "    def save(self, epoch=None):\n",
    "        if epoch is not None and not os.path.exists(CHECKPOINT_PATH):\n",
    "            os.mkdir(CHECKPOINT_PATH)\n",
    "        torch.save(self.state_dict(), self.get_filename(epoch=epoch))\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "# --- Lambda Layer for Custom Operations ---\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, function):\n",
    "        super(Lambda, self).__init__()\n",
    "        self.function = function\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.function(x)\n",
    "\n",
    "# --- Generator Model ---\n",
    "class Generator(SavableModule):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__(filename=\"generator.to\")\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.ConvTranspose3d(LATENT_CODE_SIZE, 256, 4, 1),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.ConvTranspose3d(256, 128, 4, 2, 1),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.ConvTranspose3d(128, 64, 4, 2, 1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.ConvTranspose3d(64, 1, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape((-1, LATENT_CODE_SIZE, 1, 1, 1))\n",
    "        return self.layers(x)\n",
    "\n",
    "    def generate(self, sample_size=1):\n",
    "        shape = torch.Size((sample_size, LATENT_CODE_SIZE))\n",
    "        x = standard_normal_distribution.sample(shape).to(self.device)\n",
    "        return self(x)\n",
    "\n",
    "# --- Discriminator Model ---\n",
    "class Discriminator(SavableModule):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__(filename=\"discriminator.to\")\n",
    "        self.use_sigmoid = True\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv3d(1, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv3d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv3d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv3d(256, 1, 4, 1, 0, bias=False),\n",
    "            Lambda(lambda x: torch.sigmoid(x) if self.use_sigmoid else x)\n",
    "        )\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) < 5:\n",
    "            x = x.unsqueeze(1)\n",
    "        return self.layers(x).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîÅ Section 5: Training Logic and Checkpoint Resume\n",
    "\n",
    "This section defines the GAN training loop using Binary Cross-Entropy loss and optimizers for both Generator and Discriminator. It also includes logic to resume training from the last saved checkpoint, ensuring training progress isn‚Äôt lost between runs.\n",
    "\n",
    "üß† The `train()` function handles real vs fake discrimination, generator updates, loss logging, and periodic model saving.\n",
    "\n",
    "üìã Losses and discriminator predictions are logged per epoch for visualization and analysis.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: train_gan.py\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "\n",
    "# --- Loss Function ---\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# --- Helper: Find Last Saved Epoch ---\n",
    "def find_last_saved_epoch():\n",
    "    max_epoch = 0\n",
    "    for f in os.listdir(CHECKPOINT_PATH):\n",
    "        match = re.match(r'generator-epoch-(\\d{5})\\.to', f)\n",
    "        if match:\n",
    "            epoch = int(match.group(1))\n",
    "            if epoch > max_epoch:\n",
    "                max_epoch = epoch\n",
    "    return max_epoch\n",
    "\n",
    "\n",
    "# Source: embedded from previous section (fixed scope)\n",
    "\n",
    "# Initialize models\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Set up optimizers INSIDE global scope so train() can use them\n",
    "generator_optimizer = torch.optim.Adam(\n",
    "    generator.parameters(),\n",
    "    lr=LEARNING_RATE_G,\n",
    "    betas=(BETA1, 0.999)\n",
    ")\n",
    "\n",
    "discriminator_optimizer = torch.optim.Adam(\n",
    "    discriminator.parameters(),\n",
    "    lr=LEARNING_RATE_D,\n",
    "    betas=(BETA1, 0.999)\n",
    ")\n",
    "\n",
    "# --- Training Function ---\n",
    "def train():\n",
    "    global log_file\n",
    "\n",
    "    for epoch_num in range(start_epoch_global + 1, TOTAL_TARGET_EPOCHS + 1):\n",
    "        d_losses, g_losses = [], []\n",
    "        d_preds_real, d_preds_fake = [], []\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        for i, real_voxels in enumerate(data_loader):\n",
    "            real_voxels = real_voxels.to(device)\n",
    "            current_batch_size = real_voxels.size(0)\n",
    "\n",
    "            real_labels = torch.full((current_batch_size,), 1.0, device=device)\n",
    "            fake_labels = torch.full((current_batch_size,), 0.0, device=device)\n",
    "\n",
    "            # --- Train Discriminator ---\n",
    "            discriminator_optimizer.zero_grad()\n",
    "            output_real = discriminator(real_voxels).view(-1)\n",
    "            d_loss_real = criterion(output_real, real_labels)\n",
    "            d_loss_real.backward()\n",
    "            d_preds_real.append(torch.sigmoid(output_real).mean().item())\n",
    "\n",
    "            noise = torch.randn(current_batch_size, LATENT_CODE_SIZE, device=device)\n",
    "            fake_voxels = generator(noise)\n",
    "            output_fake = discriminator(fake_voxels.detach()).view(-1)\n",
    "            d_loss_fake = criterion(output_fake, fake_labels)\n",
    "            d_loss_fake.backward()\n",
    "            d_preds_fake.append(torch.sigmoid(output_fake).mean().item())\n",
    "\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            discriminator_optimizer.step()\n",
    "\n",
    "            # --- Train Generator ---\n",
    "            generator_optimizer.zero_grad()\n",
    "            output_gen = discriminator(fake_voxels).view(-1)\n",
    "            g_loss = criterion(output_gen, real_labels)\n",
    "            g_loss.backward()\n",
    "            generator_optimizer.step()\n",
    "\n",
    "            d_losses.append(d_loss.item())\n",
    "            g_losses.append(g_loss.item())\n",
    "\n",
    "        # --- Epoch Summary ---\n",
    "        avg_d_loss = sum(d_losses) / len(d_losses)\n",
    "        avg_g_loss = sum(g_losses) / len(g_losses)\n",
    "        avg_d_real = sum(d_preds_real) / len(d_preds_real)\n",
    "        avg_d_fake = sum(d_preds_fake) / len(d_preds_fake)\n",
    "\n",
    "        print(f\"Epoch {epoch_num}/{TOTAL_TARGET_EPOCHS} - D_Loss: {avg_d_loss:.4f}, G_Loss: {avg_g_loss:.4f}, D(Real): {avg_d_real:.4f}, D(Fake): {avg_d_fake:.4f}\")\n",
    "        log_file.write(f\"{epoch_num},{time.time() - epoch_start_time:.1f},{avg_d_loss:.4f},{avg_g_loss:.4f},{avg_d_real:.4f},{avg_d_fake:.4f}\\n\")\n",
    "        log_file.flush()\n",
    "\n",
    "        if epoch_num % SAVE_EVERY_N_EPOCHS == 0 or epoch_num == TOTAL_TARGET_EPOCHS:\n",
    "            generator.save(epoch=epoch_num)\n",
    "            discriminator.save(epoch=epoch_num)\n",
    "            print(f\"Models saved at epoch {epoch_num}.\")\n",
    "\n",
    "    print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Section 6: Entry Point and Execution\n",
    "\n",
    "This block initializes the models, resumes training from the last saved epoch if applicable, opens the log file for recording metrics, and begins the training process. By encapsulating it in a main guard (`if __name__ == '__main__':`), the code stays safe and executable in both notebook and script form.\n",
    "\n",
    "üìã You can adjust the resume epoch, logging behavior, or total training epochs here without modifying the core `train()` loop.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: train_gan.py\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- Resume from last saved epoch ---\n",
    "    start_epoch_global = find_last_saved_epoch()\n",
    "    print(f\"Resuming from epoch {start_epoch_global}.\")\n",
    "    if start_epoch_global > 0:\n",
    "        generator.load(epoch=start_epoch_global)\n",
    "        discriminator.load(epoch=start_epoch_global)\n",
    "        print(\"Models loaded successfully from checkpoint.\")\n",
    "\n",
    "    # --- Open log file for metric recording ---\n",
    "    log_filename = os.path.join(MODEL_PATH, \"log.txt\")\n",
    "    log_file = open(log_filename, \"a\")\n",
    "\n",
    "    # --- Begin training ---\n",
    "    train()\n",
    "\n",
    "    # --- Close log file when done ---\n",
    "    log_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé® Section 7: Shape Generation and Visualization\n",
    "\n",
    "This section loads the trained Generator model from a selected epoch and uses it to generate new voxel shapes from random latent vectors. The output shapes can be visualized as ASCII text slices using `create_text_slice()` or rendered in 3D if the rendering modules are available.\n",
    "\n",
    "üì∏ This stage showcases what the GAN has learned and lets us preview creative voxel outputs. You can customize sample size, checkpoint epoch, and visualization method.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: visualization.py + generator preview\n",
    "\n",
    "# --- Optional Visualization Helpers ---\n",
    "def create_text_slice(voxel_data, threshold=0.0):\n",
    "    \"\"\"\n",
    "    Creates a slice-by-slice text view of voxel tensor for previewing shape.\n",
    "    Voxels with value above the threshold are shown as '*', below as ' '.\n",
    "    \"\"\"\n",
    "    voxel_data = voxel_data.detach().cpu().numpy()\n",
    "    shape = voxel_data.shape\n",
    "    print(f\"Voxel shape: {shape}\")\n",
    "    for slice_index in range(shape[2]):\n",
    "        print(f\"\\nSlice {slice_index:02d}\")\n",
    "        for row in range(shape[1]):\n",
    "            line = \"\"\n",
    "            for col in range(shape[0]):\n",
    "                line += \"*\" if voxel_data[col][row][slice_index] > threshold else \" \"\n",
    "            print(line)\n",
    "\n",
    "# --- Generate and Visualize Samples ---\n",
    "# Load a trained generator from a specific epoch\n",
    "preview_epoch = TOTAL_TARGET_EPOCHS  # or any previously saved epoch like 080\n",
    "generator.load(epoch=preview_epoch)\n",
    "print(f\"Generator loaded from epoch {preview_epoch}\")\n",
    "\n",
    "# Sample new voxel shape\n",
    "with torch.no_grad():\n",
    "    generated_voxel = generator.generate(sample_size=1)[0, 0]  # [batch, channel, ...]\n",
    "\n",
    "# Show ASCII slice preview\n",
    "print(\"\\n--- Voxel Slice Preview ---\")\n",
    "create_text_slice(generated_voxel, threshold=0.05)\n",
    "\n",
    "# Optional: call MeshRenderer if available (skipped here)\n",
    "# You can integrate rendering code here if graphics libraries are configured\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
